//! Integration test demonstrating manual aggregation without proc macros.
//!
//! This test shows how the aggregation traits work together by manually implementing
//! all the required traits for a realistic metrics scenario.

use metrique_aggregation::aggregate::{AggregateValue, AggregatableEntry, AggregatedEntry};
use metrique_aggregation::sink::TypedAggregatingEntrySink;
use metrique_aggregation::{histogram::Histogram, Counter};
use metrique_writer::{Entry, EntryWriter};
use std::borrow::Cow;
use std::time::Duration;
use assert2::check;

/// A request metric that tracks operation, status, count, and latency.
#[derive(Clone)]
struct RequestMetrics {
    operation: &'static str,
    status_code: u16,
    request_count: u64,
    latency: Duration,
}

/// The aggregated version that accumulates multiple RequestMetrics.
struct AggregatedRequestMetrics {
    key: (&'static str, u16),
    request_count: u64,
    latency: Histogram<Duration>,
}

// Implement Entry for the source metrics
impl Entry for RequestMetrics {
    fn write<'a>(&'a self, writer: &mut impl EntryWriter<'a>) {
        writer.value("Operation", &self.operation);
        writer.value("StatusCode", &self.status_code);
        writer.value("RequestCount", &self.request_count);
        writer.value("Latency", &self.latency);
    }

    fn sample_group(&self) -> impl Iterator<Item = (Cow<'static, str>, Cow<'static, str>)> {
        std::iter::empty()
    }
}

// Implement Entry for the aggregated metrics
impl Entry for AggregatedRequestMetrics {
    fn write<'a>(&'a self, writer: &mut impl EntryWriter<'a>) {
        writer.value("Operation", &self.key.0);
        writer.value("StatusCode", &self.key.1);
        writer.value("RequestCount", &self.request_count);
        // Note: In a real implementation generated by proc macro, the histogram
        // would be closed and written properly. For this manual test, we skip it
        // to avoid the complexity of dealing with &self vs consuming self.
    }

    fn sample_group(&self) -> impl Iterator<Item = (Cow<'static, str>, Cow<'static, str>)> {
        std::iter::empty()
    }
}

// Implement AggregatableEntry - defines the key and how to create aggregators
impl AggregatableEntry for RequestMetrics {
    type Key = (&'static str, u16);
    type Aggregated = AggregatedRequestMetrics;

    fn new_aggregated(key: Self::Key) -> Self::Aggregated {
        AggregatedRequestMetrics {
            key,
            request_count: Counter::init(),
            latency: Histogram::init(),
        }
    }

    fn key(&self) -> Self::Key {
        (self.operation, self.status_code)
    }
}

// Implement AggregatedEntry - defines how to merge entries
impl AggregatedEntry for AggregatedRequestMetrics {
    type Key = (&'static str, u16);
    type Source = RequestMetrics;

    fn aggregate_into(&mut self, entry: &Self::Source) {
        Counter::aggregate(&mut self.request_count, &entry.request_count);
        Histogram::aggregate(&mut self.latency, &entry.latency);
    }
}

#[test]
fn test_manual_aggregation_flow() {
    // Create an aggregating sink
    let sink = TypedAggregatingEntrySink::<RequestMetrics>::new();

    // Simulate multiple requests coming in
    sink.append(RequestMetrics {
        operation: "GetUser",
        status_code: 200,
        request_count: 1,
        latency: Duration::from_millis(45),
    });

    sink.append(RequestMetrics {
        operation: "GetUser",
        status_code: 200,
        request_count: 1,
        latency: Duration::from_millis(52),
    });

    sink.append(RequestMetrics {
        operation: "GetUser",
        status_code: 200,
        request_count: 1,
        latency: Duration::from_millis(38),
    });

    sink.append(RequestMetrics {
        operation: "GetUser",
        status_code: 500,
        request_count: 1,
        latency: Duration::from_millis(120),
    });

    sink.append(RequestMetrics {
        operation: "UpdateUser",
        status_code: 200,
        request_count: 1,
        latency: Duration::from_millis(85),
    });

    // Drain aggregated results
    let results = sink.drain();

    // Should have 3 unique keys: (GetUser, 200), (GetUser, 500), (UpdateUser, 200)
    check!(results.len() == 3);

    // Find the GetUser/200 aggregation
    let get_user_200 = results
        .iter()
        .find(|r| r.key == ("GetUser", 200))
        .expect("Should have GetUser/200 aggregation");

    // Should have aggregated 3 requests
    check!(get_user_200.request_count == 3);

    // The latency histogram has aggregated 3 observations
    // In a real scenario, this would be closed and emitted to the backend

    // Find the GetUser/500 aggregation
    let get_user_500 = results
        .iter()
        .find(|r| r.key == ("GetUser", 500))
        .expect("Should have GetUser/500 aggregation");

    check!(get_user_500.request_count == 1);

    // Find the UpdateUser/200 aggregation
    let update_user_200 = results
        .iter()
        .find(|r| r.key == ("UpdateUser", 200))
        .expect("Should have UpdateUser/200 aggregation");

    check!(update_user_200.request_count == 1);
}

#[test]
fn test_counter_only_aggregation() {
    #[derive(Clone)]
    struct SimpleMetrics {
        operation: &'static str,
        count: u64,
    }

    struct AggregatedSimpleMetrics {
        key: &'static str,
        count: u64,
    }

    impl Entry for SimpleMetrics {
        fn write<'a>(&'a self, writer: &mut impl EntryWriter<'a>) {
            writer.value("Operation", &self.operation);
            writer.value("Count", &self.count);
        }
        fn sample_group(&self) -> impl Iterator<Item = (Cow<'static, str>, Cow<'static, str>)> {
            std::iter::empty()
        }
    }

    impl Entry for AggregatedSimpleMetrics {
        fn write<'a>(&'a self, writer: &mut impl EntryWriter<'a>) {
            writer.value("Operation", &self.key);
            writer.value("Count", &self.count);
        }
        fn sample_group(&self) -> impl Iterator<Item = (Cow<'static, str>, Cow<'static, str>)> {
            std::iter::empty()
        }
    }

    impl AggregatableEntry for SimpleMetrics {
        type Key = &'static str;
        type Aggregated = AggregatedSimpleMetrics;

        fn new_aggregated(key: Self::Key) -> Self::Aggregated {
            AggregatedSimpleMetrics {
                key,
                count: Counter::init(),
            }
        }

        fn key(&self) -> Self::Key {
            self.operation
        }
    }

    impl AggregatedEntry for AggregatedSimpleMetrics {
        type Key = &'static str;
        type Source = SimpleMetrics;

        fn aggregate_into(&mut self, entry: &Self::Source) {
            Counter::aggregate(&mut self.count, &entry.count);
        }
    }

    let sink = TypedAggregatingEntrySink::<SimpleMetrics>::new();

    // Add many small counts
    for _ in 0..100 {
        sink.append(SimpleMetrics {
            operation: "read",
            count: 1,
        });
    }

    for _ in 0..50 {
        sink.append(SimpleMetrics {
            operation: "write",
            count: 1,
        });
    }

    let results = sink.drain();
    check!(results.len() == 2);

    let read = results.iter().find(|r| r.key == "read").unwrap();
    check!(read.count == 100);

    let write = results.iter().find(|r| r.key == "write").unwrap();
    check!(write.count == 50);
}

#[test]
fn test_histogram_only_aggregation() {
    #[derive(Clone)]
    struct LatencyMetrics {
        endpoint: &'static str,
        latency: Duration,
    }

    struct AggregatedLatencyMetrics {
        key: &'static str,
        latency: Histogram<Duration>,
    }

    impl Entry for LatencyMetrics {
        fn write<'a>(&'a self, writer: &mut impl EntryWriter<'a>) {
            writer.value("Endpoint", &self.endpoint);
            writer.value("Latency", &self.latency);
        }
        fn sample_group(&self) -> impl Iterator<Item = (Cow<'static, str>, Cow<'static, str>)> {
            std::iter::empty()
        }
    }

    impl Entry for AggregatedLatencyMetrics {
        fn write<'a>(&'a self, writer: &mut impl EntryWriter<'a>) {
            writer.value("Endpoint", &self.key);
            // Note: Histogram writing skipped in manual test for simplicity
        }
        fn sample_group(&self) -> impl Iterator<Item = (Cow<'static, str>, Cow<'static, str>)> {
            std::iter::empty()
        }
    }

    impl AggregatableEntry for LatencyMetrics {
        type Key = &'static str;
        type Aggregated = AggregatedLatencyMetrics;

        fn new_aggregated(key: Self::Key) -> Self::Aggregated {
            AggregatedLatencyMetrics {
                key,
                latency: Histogram::init(),
            }
        }

        fn key(&self) -> Self::Key {
            self.endpoint
        }
    }

    impl AggregatedEntry for AggregatedLatencyMetrics {
        type Key = &'static str;
        type Source = LatencyMetrics;

        fn aggregate_into(&mut self, entry: &Self::Source) {
            Histogram::aggregate(&mut self.latency, &entry.latency);
        }
    }

    let sink = TypedAggregatingEntrySink::<LatencyMetrics>::new();

    // Add various latencies for the same endpoint
    sink.append(LatencyMetrics {
        endpoint: "/api/users",
        latency: Duration::from_millis(10),
    });
    sink.append(LatencyMetrics {
        endpoint: "/api/users",
        latency: Duration::from_millis(50),
    });
    sink.append(LatencyMetrics {
        endpoint: "/api/users",
        latency: Duration::from_millis(100),
    });
    sink.append(LatencyMetrics {
        endpoint: "/api/users",
        latency: Duration::from_millis(25),
    });

    let results = sink.drain();
    check!(results.len() == 1);

    let _api_users = results.iter().find(|r| r.key == "/api/users").unwrap();
    
    // Verify the histogram exists and aggregated observations
    // In production, this would be closed and emitted to the metrics backend
}
